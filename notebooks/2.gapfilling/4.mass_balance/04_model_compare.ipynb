{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e32606f",
   "metadata": {},
   "source": [
    "# Compare Mannual curated model with the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from cobra.io import read_sbml_model, load_json_model\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "ext_dir = '/../../../data/external'\n",
    "phenomics = '/../../phenomics'\n",
    "gapfilling = '/../gapfilling'\n",
    "mass_balance = '../4.mass_balance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea511298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mass = read_sbml_model(f\"{os.getcwd()}/{mass_balance}/Salb-GEM-Biosustain.xml\")\n",
    "model_ori = read_sbml_model(f\"{os.getcwd()}/{ext_dir}/Salb-GEM-Updated.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd28405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b11f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2159a",
   "metadata": {},
   "source": [
    "# Calculate activity based on biolog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of bigg and biolog model\n",
    "bigg_map_dir = os.getcwd() + ext_dir + \"/\" + \"biolog_bigg_map.csv\"\n",
    "biolog_bigg_map = pd.read_csv(bigg_map_dir)\n",
    "\n",
    "# Import processed biolog data based on DuctApe result\n",
    "bio_data_dir = os.getcwd() + phenomics + \"/\" + 'phenome_J1074.tsv'\n",
    "bio_data = pd.read_table(bio_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join two tables together\n",
    "bio_data.rename(columns={\"#plate_id\": \"plate_id\"}, inplace=True)\n",
    "bio_data['index'] = bio_data['plate_id'] + \"_\" + bio_data['well_id']\n",
    "\n",
    "biolog_bigg_map.rename(columns={\"#plate_id\": \"plate_id\"}, inplace=True)\n",
    "bio_data_merged = bio_data.merge(biolog_bigg_map[['index', 'bigg', 'exchange']], on='index', how='left')\n",
    "\n",
    "bio_data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the samples that grow or not grow based on activity and replicas\n",
    "# Vote: >=3 = growth, >2/3 replicates = grow\n",
    "\n",
    "def calculate_agreed_activity(bio_data, activity_cutoff=3, num_agreed_replicas=2):\n",
    "    \"\"\"\n",
    "    Based on the activity data from the microarray experiment, using activity cutoff and\n",
    "    agreed number replicates cutoff to make a dataframe that contains final activity info.\n",
    "    \n",
    "    Input:\n",
    "    activity_cutoff: an integer between 0-9, if the activity is more than cutoff, it \n",
    "    means the strain grows.\n",
    "    num_agreed_replicas: an integer, if the number of replicates agrees more than\n",
    "    num_agreed_replicas times, it means the replicas agrees with the experimental result.\n",
    "    \n",
    "    Output:\n",
    "    A dataframe that\n",
    "    \"\"\"\n",
    "    agreed_bio_data = pd.DataFrame(columns=[\n",
    "    'index', 'activity', 'chemical', 'category', 'moa', 'bigg', 'exchange'])\n",
    "    \n",
    "    # for each column 'index'\n",
    "    for index, group in bio_data.groupby('index'):\n",
    "        first_row = group.iloc[0]\n",
    "        if (group['activity'] >= activity_cutoff).sum() >= num_agreed_replicas:\n",
    "            agreed_bio_data = agreed_bio_data.append({'index': index, \n",
    "                                    'activity': True, \n",
    "                                    'chemical': first_row['chemical'], \n",
    "                                    'category':  first_row['category'], \n",
    "                                    'moa':  first_row['moa'],\n",
    "                                    'bigg': first_row['bigg'],\n",
    "                                    'exchange': first_row['exchange']}, ignore_index=True)\n",
    "        else:\n",
    "            agreed_bio_data = agreed_bio_data.append({'index': index, \n",
    "                                    'activity': False, \n",
    "                                    'chemical': first_row['chemical'], \n",
    "                                    'category':  first_row['category'], \n",
    "                                    'moa':  first_row['moa'],\n",
    "                                    'bigg': first_row['bigg'],\n",
    "                                    'exchange': first_row['exchange']}, ignore_index=True)\n",
    "    return agreed_bio_data\n",
    "\n",
    "\n",
    "activity_cutoff = 3\n",
    "num_agreed_replicas = 2\n",
    "agreed_bio_data = calculate_agreed_activity(bio_data_merged, activity_cutoff, num_agreed_replicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb795b",
   "metadata": {},
   "source": [
    "# Test model simulations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define media and model simulation functions\n",
    "media = {\n",
    "    \"Biolog_base\": {  # based on ecocyc\n",
    "        \"EX_cl_e\": -1000,\n",
    "        \"EX_na1_e\": -1000,\n",
    "        \"EX_nh4_e\": -1000,\n",
    "        \"EX_pi_e\": -1000,\n",
    "        \"EX_k_e\": -1000,\n",
    "        \"EX_so4_e\": -1000,\n",
    "        \"EX_mg2_e\": -1000,\n",
    "        \"EX_fe2_e\": -1000,\n",
    "        # based on conditions, essentials and trace requirements\n",
    "        \"EX_o2_e\": -1000,\n",
    "        \"EX_co2_e\": -1000.0,\n",
    "        \"EX_h_e\": -1000.0,\n",
    "        \"EX_mn2_e\": -1000.0,\n",
    "        \"EX_zn2_e\": -1000.0,\n",
    "        \"EX_ca2_e\": -1000.0,\n",
    "        \"EX_ni2_e\": -1000.0,\n",
    "        \"EX_cu2_e\": -1000.0,\n",
    "        \"EX_cobalt2_e\": -1000.0,\n",
    "        \"EX_h2o_e\": -1000.0,\n",
    "        \"EX_mobd_e\": -1000.0,\n",
    "    },\n",
    "    \"C-Source\": {},  # no further modification is needed\n",
    "    \"N-Source\": {  # remove ammonia and add C-source\n",
    "        \"EX_nh4_e\": 0,\n",
    "        \"EX_pyr_e\": -20,\n",
    "    },\n",
    "    \"P-Source\": {  # remove phosphate and add C-source\n",
    "        \"EX_pi_e\": 0,\n",
    "        \"EX_pyr_e\": -20,\n",
    "    },\n",
    "    \"S-Source\": {  # remove sulfate and add C-source\n",
    "        \"EX_so4_e\": 0,\n",
    "        \"EX_pyr_e\": -20,\n",
    "    },\n",
    "}\n",
    "\n",
    "def test_model_wrt_biolog(\n",
    "    moa: str,\n",
    "    additional_exchange: str,\n",
    "    model: cobra.core.Model,\n",
    "    media: dict = media,\n",
    "    cutoff: float = 0.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    Tests model with given media and returns True/False based on cutoff growth rate.\n",
    "    If additional exchange reaction is not in the model, returns NaN.\n",
    "\n",
    "    Input\n",
    "    model: metabolic model\n",
    "    moa: the mechanism of action of the biolog well test\n",
    "    additional_exchange: the exchange reaction to be added to the model for the well\n",
    "    media: a dictionary of media conditions to set for a given biolog test\n",
    "    cutoff: the cutoff growth rate for boolean return\n",
    "\n",
    "    Output\n",
    "    True/False based on cutoff growth rate or NaN if additional exchange reaction is not\n",
    "     in the model\n",
    "    \"\"\"\n",
    "    # drop out quickly if there is no exchange reaction to use in the model\n",
    "    if additional_exchange not in model.reactions:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    with model:\n",
    "        # reset original media\n",
    "        for exchange in model.medium.keys():\n",
    "            model.reactions.get_by_id(exchange).lower_bound = 0\n",
    "\n",
    "        # set base media\n",
    "        for exchange, value in media[\"Biolog_base\"].items():\n",
    "            model.reactions.get_by_id(exchange).lower_bound = value\n",
    "\n",
    "        for exchange, value in media[moa.split(\",\")[0]].items():\n",
    "            model.reactions.get_by_id(exchange).lower_bound = value\n",
    "\n",
    "        # add exchange reaction. lower bound is high but we are only looking for T/F/NAN\n",
    "        model.reactions.get_by_id(additional_exchange).lower_bound = -20\n",
    "\n",
    "        # solve and return\n",
    "        return True if (model.slim_optimize(error_value=0) >= cutoff) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the TP, FP, TN and FN\n",
    "\n",
    "def pred_vs_actual(bio_data, actual, predicted):\n",
    "    \"\"\"\n",
    "    This is a function that summarizes the growth activities by comparing simulated model \n",
    "    and actual experimental values.\n",
    "    \n",
    "    Input:\n",
    "    bio_data: A dataframe that contains one column of model siumlation and one column \n",
    "    of actual activity.\n",
    "    actual: A string that is the column name of experimental activity level.\n",
    "    predicted: A string that is the column name of model value.\n",
    "    \n",
    "    Output:\n",
    "    A 2 by 2 dataframe that that contains the sum of matched True/False values.\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.crosstab(bio_data[actual], bio_data[predicted], rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3efc0c",
   "metadata": {},
   "source": [
    "# Compare two different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test original model with cutoff\n",
    "\n",
    "agreed_bio_data[\"model_simulation\" + \"_0.05\" + \"_model_ori\"] = agreed_bio_data.apply(\n",
    "    func=lambda row: test_model_wrt_biolog(\n",
    "        moa=row[\"moa\"],\n",
    "        additional_exchange=row[\"exchange\"],\n",
    "        model=model_ori,\n",
    "        media=media,\n",
    "        cutoff=0.05,\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreed_bio_data[\"model_simulation\" + \"_0.05\"] = agreed_bio_data.apply(\n",
    "    func=lambda row: test_model_wrt_biolog(\n",
    "        moa=row[\"moa\"],\n",
    "        additional_exchange=row[\"exchange\"],\n",
    "        model=model_mass,\n",
    "        media=media,\n",
    "        cutoff=0.05,\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff 0.05\n",
    "confusion_matrix_005_ori = pd.crosstab(agreed_bio_data['activity'], agreed_bio_data['model_simulation_0.05_model_ori'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"cutoff 0.05\\n\", confusion_matrix_005_ori)\n",
    "\n",
    "confusion_matrix_005_mass = pd.crosstab(agreed_bio_data['activity'], agreed_bio_data['model_simulation_0.05'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"cutoff 0.05\\n\", confusion_matrix_005_mass)\n",
    "\n",
    "cm_list = [confusion_matrix_005_ori, confusion_matrix_005_mass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreed_bio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# calculate accuracy, precision, sensitivity, specificity, and f-Score for each confusion matrix\n",
    "# plot all the result into a graph\n",
    "def calculate_stats(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Description: A function that automatically calculate 5 essential statistics\n",
    "    \n",
    "    Input: \n",
    "    confusion_matrix: A 2 by 2 dataframe. It's a confusion matrix with row being \n",
    "    actual and column being predicted.\n",
    "    \n",
    "    Output: \n",
    "    result: A dictionary of essential statistics, including accuracy, precision, sensitivity, \n",
    "    specificity, f score. \n",
    "    \"\"\"\n",
    "    result = {}\n",
    "\n",
    "    result['TN'] = tn = confusion_matrix.iloc[0, 0]\n",
    "    result['FP'] = fp = confusion_matrix.iloc[0, 1]\n",
    "    result['FN'] = fn = confusion_matrix.iloc[1, 0]\n",
    "    result['TP'] = tp = confusion_matrix.iloc[1, 1]\n",
    "\n",
    "    result['accuracy'] = (tp + tn) / (tp + tn + fp + fn)\n",
    "    result['precision'] = precision = tp / (tp + fp)\n",
    "    result['sensitivity'] = sensitivity = tp / (tp + fn)\n",
    "    result['specificity'] = tn / (tn + fp)\n",
    "    result['f_score'] = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "stats_01 = calculate_stats(confusion_matrix_005_ori)\n",
    "stats_02 = calculate_stats(confusion_matrix_005_mass)\n",
    "\n",
    "plt.figure(figsize=(10, 4)) \n",
    "x = [1, 2]\n",
    "labels = ['accuracy', 'precision', 'sensitivity', 'specificity', 'f_score']\n",
    "for i, key in enumerate(labels):\n",
    "    y = [stats_01[key], stats_02[key]]\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.bar(x, y, width=0.5, color=['tab:red', 'tab:blue'])\n",
    "    plt.title(key)\n",
    "    plt.xticks(x, ['Original Model', 'Final Model'], rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d8818",
   "metadata": {},
   "source": [
    "# Testability of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41492986",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreed_bio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4890d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the testable & untestable number of sources from simulation\n",
    "for element in \"CNPS\":\n",
    "    num1 = len(\n",
    "        agreed_bio_data[\n",
    "            (agreed_bio_data.xs(\"moa\", axis=1).str.startswith(f\"{element}-Source\"))\n",
    "            & ~(agreed_bio_data.xs(\"model_simulation_0.05_model_ori\", axis=1).isna())\n",
    "        ]\n",
    "    )\n",
    "    num2 = len(\n",
    "        agreed_bio_data[\n",
    "            (agreed_bio_data.xs(\"moa\", axis=1).str.startswith(f\"{element}-Source\"))\n",
    "            & (agreed_bio_data.xs(\"model_simulation_0.05\", axis=1).isna())\n",
    "        ]\n",
    "    )\n",
    "    print(f\"{element}-sources: Number of computationally testable: {num1} and untestable: {num2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the untestable ones\n",
    "count = 0\n",
    "for element in \"CNPS\":\n",
    "    chemicals = agreed_bio_data[\n",
    "        (agreed_bio_data.xs(\"moa\", axis=1).str.startswith(f\"{element}-Source\"))\n",
    "        & (agreed_bio_data.xs(\"model_simulation_0.05\", axis=1).isna())\n",
    "        & (agreed_bio_data.xs(\"activity\", axis=1))\n",
    "    ][\"chemical\"].unique()\n",
    "    count += len(chemicals)\n",
    "    \n",
    "    print(f\"{element}-sources: \\nUntestable chemicals with positive growth in experiment: \\n{chemicals}\\n\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1b492",
   "metadata": {},
   "source": [
    "# Find out false positives & negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911fc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the inconsistency between predicted and simulated ones\n",
    "print(f\"False positives (actual false, predicted true):\\n\")\n",
    "print(agreed_bio_data[\n",
    "    ~(agreed_bio_data.xs(\"activity\", axis=1))\n",
    "    & agreed_bio_data.xs(\"model_simulation_0.05\", axis=1)\n",
    "    ][\"chemical\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ba058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFalse negative (actual true, predicted false):\\n\")\n",
    "agreed_bio_data_nan_drop = agreed_bio_data[agreed_bio_data['model_simulation_0.05'].notna()]\n",
    "false_negative = agreed_bio_data_nan_drop[\n",
    "    agreed_bio_data_nan_drop.xs(\"activity\", axis=1)\n",
    "    & ~(agreed_bio_data_nan_drop.xs(\"model_simulation_0.05\", axis=1))\n",
    "    ][\"chemical\"].unique()\n",
    "\n",
    "print(false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeabd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_mass:\n",
    "    model.medium['EX_gl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2fc6d6",
   "metadata": {},
   "source": [
    "# Compare all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f807b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with your data\n",
    "df = pd.read_excel(\"model_comparison.xlsx\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ade7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to long format for seaborn\n",
    "df_long = pd.melt(df, id_vars=['Model'], \n",
    "                 value_vars=['Accuracy', 'Precision', 'Sensitivity', 'F1 Score'],\n",
    "                 var_name='Metric', value_name='Value')\n",
    "\n",
    "# Set up a color palette that clearly distinguishes between models\n",
    "palette = sns.color_palette(\"viridis\", 5)\n",
    "\n",
    "# Create the plot with seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the grouped bar plot\n",
    "ax = sns.barplot(\n",
    "    data=df_long,\n",
    "    x=\"Metric\", y=\"Value\", hue=\"Model\",\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title('Model Performance Comparison', fontsize=16)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_ylim(0.7, 1.05)\n",
    "\n",
    "# Add value labels on top of bars - compatible with older matplotlib versions\n",
    "for container in ax.containers:\n",
    "    bars = container.get_children()\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2, \n",
    "            height + 0.005, \n",
    "            f'{height:.3f}', \n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=9\n",
    "        )\n",
    "\n",
    "# Add a legend with a better position\n",
    "ax.legend(title='Model', bbox_to_anchor=(0.22, 1))\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"model_performance_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "width = 0.2  # width of the bars\n",
    "\n",
    "# Setting the positions of the bars\n",
    "positions = list(range(len(df['Model'])))\n",
    "positions_precision = [x + width for x in positions]\n",
    "positions_sensitivity = [x + width * 2 for x in positions]\n",
    "positions_f1 = [x + width * 3 for x in positions]\n",
    "\n",
    "# Creating the bar plots\n",
    "bars1 = ax.bar(positions, df['Accuracy'], width, label='Accuracy')\n",
    "bars2 = ax.bar(positions_precision, df['Precision'], width, label='Precision')\n",
    "bars3 = ax.bar(positions_sensitivity, df['Sensitivity'], width, label='Sensitivity')\n",
    "bars4 = ax.bar(positions_f1, df['F1 Score'], width, label='F1 Score')\n",
    "\n",
    "# Adding labels on top of the bars\n",
    "for bars in [bars1, bars2, bars3, bars4]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom', ha='center')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Metrics')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks([p + width * 1.5 for p in positions])\n",
    "ax.set_xticklabels(df['Model'])\n",
    "\n",
    "# Adding a legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot with guidelines\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c729b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "# Number of models\n",
    "num_models = len(df)\n",
    "\n",
    "# Finding the maximum value across all confusion matrices for a consistent color scale\n",
    "max_value = df[['False Positive', 'True Positive', 'False Negative', 'True Negative']].values.max()\n",
    "\n",
    "# Creating a subplot for each model's confusion matrix\n",
    "fig, axes = plt.subplots(1, num_models, figsize=(15,4))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Extracting confusion matrix data for each model\n",
    "    cm_data = [[df.iloc[i]['True Positive'], df.iloc[i]['False Negative']],\n",
    "               [df.iloc[i]['False Positive'], df.iloc[i]['True Negative']]]\n",
    "    \n",
    "    # Creating a heatmap for the confusion matrix with a consistent color scale\n",
    "    sns.heatmap(cm_data, annot=True, fmt='d', cmap='Blues', vmax=max_value, ax=ax, cbar=False)\n",
    "\n",
    "    # Adding titles and labels\n",
    "    ax.set_title(df['Model'][i])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.xaxis.set_ticklabels(['Positive', 'Negative'])\n",
    "    ax.yaxis.set_ticklabels(['Positive', 'Negative'])\n",
    "\n",
    "# Main title for the entire figure\n",
    "plt.suptitle(\"Model's Comparison through Confusion Matrix \", fontsize=16, y=1.0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
